{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3W1mKwuZB7"
      },
      "source": [
        "**MODELOS DE EMBEDDINGS BASADOS EN WORD2VEC**\n",
        "\n",
        "*John Atkinson*\n",
        "\n",
        "Este programa utiliza  crea y utiliza modelos de embeddings de lenguaje basado en mètodos del tipo Word2Vec.\n",
        "\n",
        "Primero, necesitamos instalar algunos paquetes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfmS1KKiun1t"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZpOLHcVuo2o"
      },
      "source": [
        "Montamos nuestro *Drive* donde se encuentra la carpeta CORPUS con documentos separados por tema:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew3Tgj9PuOjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c69e51-6de5-4dcc-8dbd-9f01a0068d05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/CORPUS"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/CORPUS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UdMswDzuwB7"
      },
      "source": [
        "Debemos importar algunas bibliotecas  y utilitarios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3ZXsaVjuwrC"
      },
      "source": [
        "import es_core_news_sm\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCdfEFEfvT7Q"
      },
      "source": [
        "Primero, definimos la función **EntrenarModelo(oraciones,NombreModelo)**, que permite entrenar un modelo Word2Vec a partir de un conjunto de oraciones extraída desde un corpus. El modelo generado se graba en la carpeta **NombreModelo**. Asumimos que la ventaja de entrenamiento es 2 ($windows=2$) y que el número de dimensiones o tamaño del vector es 8 ($size=8$). Note que se debe encontrar el mejor tamaño del embedding.\n",
        "\n",
        "Luego, definimos una función **CargarModelo(NombreModelo)**, que nos permitirá cargar un modelo cuando sea necesario.\n",
        "\n",
        "Note que no necesariamente debemos entrenar el modelo nosotros mismos. Podríamos cargar un modelo de embeddings que ya ha sido entrenado por alguien más."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvDmFlnDwLE4"
      },
      "source": [
        "def EntrenarModelo(oraciones,NombreModelo):\n",
        "    model = Word2Vec(oraciones, vector_size=8, window=2, min_count=1)\n",
        "    model.save(NombreModelo)\n",
        "\n",
        "def CargarModelo(NombreModelo):\n",
        "   modelo = Word2Vec.load(NombreModelo)\n",
        "   #vocabulario = [term for term in modelo.wv.vocab]\n",
        "   vocabulario = [term for term in modelo.wv.key_to_index]\n",
        "   return(modelo,vocabulario)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-qH4YzKz-mg"
      },
      "source": [
        "Además, necesitaremos una función **ObtenerEmbeddingOracion(modelo, oracion)**, que nos permitirá obtener el embedding (vector) de una oración desde un modelo entrenado. El embedding de una oración es simplemente el vector promedio de cada una de las palabras de la oración:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iOz77PFz88a"
      },
      "source": [
        "def ObtenerEmbeddingOracion(modelo, oracion):\n",
        "   Lista_vectores = []\n",
        "   for w in Tokenizar(oracion):\n",
        "       # Verificar que la palabra w exista en el modelo\n",
        "       try:\n",
        "           modelo.wv[w]\n",
        "       except KeyError:\n",
        "           continue\n",
        "       # Obtener vector de la palabra\n",
        "       vec = modelo.wv[w]\n",
        "       Lista_vectores.append(vec)\n",
        "   embedding_palabras = np.array(Lista_vectores)\n",
        "   if (len(embedding_palabras) > 0):\n",
        "        embedding_oracion = embedding_palabras.mean(axis=0)\n",
        "   else:\n",
        "        embedding_oracion = np.zeros(modelo.vector_size)\n",
        "   return(embedding_oracion)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZj5KFfkyQnX"
      },
      "source": [
        "Ahora, utilizamos algunas funciones de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA-A89OTyiy1"
      },
      "source": [
        "def PreProcesarOraciones(textos):\n",
        "    texto_limpio = []\n",
        "    for texto in textos:\n",
        "        if len(texto)!=0:\n",
        "          texto = regex.sub(' +', ' ', texto)\n",
        "          tokens = Tokenizar(texto)\n",
        "          texto_limpio.append(tokens)\n",
        "    return(texto_limpio)\n",
        "\n",
        "def Tokenizar(oracion):\n",
        "    doc = nlp(oracion)\n",
        "    tokens = [palabra.text for palabra in doc]\n",
        "    return(tokens)\n",
        "\n",
        "def CrearCorpus(path):\n",
        "  directorio = os.listdir(path)\n",
        "  corpus = []\n",
        "  doc_id = []\n",
        "  for filename  in directorio:\n",
        "     texto = open(path+filename,'r',encoding=\"latin-1\").read()\n",
        "     corpus.append(texto)\n",
        "     doc_id.append(filename)\n",
        "  return(corpus,doc_id)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En caso de ser necesario definimos una función que permite convertir una lista a un diccionario, de modo de poder acceder por clave (y no por índice):"
      ],
      "metadata": {
        "id": "Szvub8wifLU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CrearDiccionario(lista,claves):\n",
        "   dicc = {}\n",
        "   for  v in range(0,len(claves)):\n",
        "      dicc[claves[v]] = lista[v]\n",
        "   return(dicc)"
      ],
      "metadata": {
        "id": "-vqcwQ55fRBc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tTIjw2vzFMG"
      },
      "source": [
        "Ahora, ejecutamos nuestro programa principal con algunas incializaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK34lW6izLAL"
      },
      "source": [
        "PATH = \"deportes/\"\n",
        "nlp          = es_core_news_sm.load()\n",
        "corpus,docID = CrearCorpus(PATH)\n",
        "oraciones    =  PreProcesarOraciones(corpus)\n",
        "CorpusConClave  = CrearDiccionario(corpus,docID)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DAyV3uSzSRv"
      },
      "source": [
        "Entrenamos el modelo en base a las oraciones generadas previamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIh2CDtDzY_o"
      },
      "source": [
        "EntrenarModelo(oraciones,'mi_word2vec')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovHOhFoJzbEQ"
      },
      "source": [
        "Luego, cargamos el modelo entrenado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWBtEpdgzlYA"
      },
      "source": [
        "modelo, vocabulario = CargarModelo('mi_word2vec')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos, obtener el embedding de alguna palabra:"
      ],
      "metadata": {
        "id": "m3OglWudfpPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(modelo.wv['jugador'])\n",
        "print(\"\\n\")\n",
        "print(modelo.wv['pelota'])"
      ],
      "metadata": {
        "id": "t6bPS6x9cCCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-fqrq_W0sFw"
      },
      "source": [
        "Una vez que tenemos nuestro modelo cargado, podemos realizar diferentes tareas sobre los vectores de palabras u oraciones.\n",
        "\n",
        "Por ejemplo, podemos determinar la *cercanía* entre dos documentos del corpus. Para ello:\n",
        "\n",
        "1.   Tomamos el texto de cada documento.\n",
        "2.   Obtenemos sus respectivos vectores (embeddings).\n",
        "3.   Calculamos la distancia **coseno**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnDZgBz56lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cd5e2e-f156-4fb8-b388-6de35ec36a1e"
      },
      "source": [
        "doc1 = CorpusConClave['d15.txt']\n",
        "doc2 = CorpusConClave['d21.txt']\n",
        "vec1 = ObtenerEmbeddingOracion(modelo, doc1)\n",
        "vec2 = ObtenerEmbeddingOracion(modelo, doc2)\n",
        "\n",
        "similitud = 1-cosine(vec1,vec2)\n",
        "print(similitud)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8317442536354065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que la calidad del resultado depende de la cercanía real de los documentos!"
      ],
      "metadata": {
        "id": "4HwRvrMqgG-d"
      }
    }
  ]
}