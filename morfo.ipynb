{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "morfo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQQyFHf1ijOD"
      },
      "source": [
        "**ANÁLISIS MORFOLÓGICO**\n",
        "\n",
        "*John Atkinson*\n",
        "\n",
        "Este programa realiza el análisis morfológico del tipo **lematización** de textos de entrada en **Español**. El programa utiliza métodos de la biblioteca **SPaCY** para procesamiento de lenguaje natural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXmzxZG3Q8S1"
      },
      "source": [
        "Primero, debemos instalar la biblioteca SpacY. Luego, debemos cargar un modelo de SpacY pre-entrenado para textos de noticias en Español (*es_core_news_sm*) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp259tcNiu18"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ7tGVRabiYv"
      },
      "source": [
        "Una vez instaladas, utilizamos algunas bibliotecas para NLP y otros utitlitarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlF0o0U3iVna"
      },
      "source": [
        "import es_core_news_sm\n",
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0tYiozOSgaL"
      },
      "source": [
        "Luego, definimos algunas funciones que nos serán útiles.\n",
        "\n",
        "La función **LeerTexto(NombreArchivo)** lee un archivo de texto en español, lo separa según puntuaciones simples (\".\"), y retorna el texto separado en varias oraciones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaUzQs08jTFi"
      },
      "source": [
        "def LeerTexto(NombreArchivo):\n",
        "    f = open(NombreArchivo, 'r', encoding=\"utf8\")\n",
        "    texto = f.read().split('.')\n",
        "    f.close()\n",
        "    return(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL-IZSvLUbdC"
      },
      "source": [
        "Luego, definimos la función **Lematizar(oracion)**, que recibe una oración de texto, y genera un string con cada uno de los lemas de cada palabra de la oración. Para esto, se utiliza  el método **nlp(..)** de Spacy. A diferencia de otros frameworks para NLP (i.e., NLTK), SpaCY realiza varios análisis simultáneamente para una misma oración con el mismo método **nlp(..)**: lematización, POS tagging, tokenización, etc. En otras bibliotecas, cada análisis requiere métodos/funciones diferentes.\n",
        "\n",
        "Luego, generamos una lista con cada uno de los lemas obtenidos por **nlp(..)**, y se retorna un string con los lemas concatenados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUeGklIMUEBV"
      },
      "source": [
        "def Lematizar(oracion):\n",
        "   doc = nlp(oracion)\n",
        "   lemas = [token.lemma_ for token in doc]\n",
        "   return(\" \".join(lemas))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCcz0KrZI3b"
      },
      "source": [
        "Una vez definidas todas las funciones, ejecutamos nuestro programa principal que inicializa variables y métodos, e invoca a las funciones definidas previamente. \n",
        "\n",
        "Especificamos el nombre del archivo que deseamos analizar (**NO se le olvide cargarlos en su directorio!!**). Luego, inicializamos nuestro método **nlp(..)** para que cargue el modelo de NLP pre-entrenado en Español:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcZhtKMVZTBL"
      },
      "source": [
        "NOMBRE_ARCHIVO='sample.txt'\n",
        "nlp       = es_core_news_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU7MuOdCaCIp"
      },
      "source": [
        "Leemos el texto especificado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K64K6tBuaJ8U"
      },
      "source": [
        "oraciones = LeerTexto(NOMBRE_ARCHIVO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lObHjt2dzivZ"
      },
      "source": [
        "print(oraciones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdiAfgBuaNak"
      },
      "source": [
        "Creamos una lista con cada una de las oraciones del texto *lematizadas*, y luego las mostramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYsdWh3Ljj7N"
      },
      "source": [
        "texto_lematizado  = [Lematizar(oracion) for oracion in oraciones]\n",
        "print(texto_lematizado)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}